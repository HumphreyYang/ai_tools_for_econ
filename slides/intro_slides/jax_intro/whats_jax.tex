\input{../preamble}

\title{What's JAX}



\author{John Stachurski}


\date{2025}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}



\begin{frame}
    \frametitle{Topics}

    \begin{itemize}
        \item Foo
        \vspace{0.5em}
        \item Bar
        \vspace{0.5em}
    \end{itemize}

\end{frame}



    

\begin{frame}
    \frametitle{Focus on JAX}

    \url{https://jax.readthedocs.io/en/latest/}
    
            \vspace{0.5em}
    \begin{itemize}
        \item \brown{J}ust-in-time compilation
            \vspace{0.5em}
        \item \brown{A}utomatic differentiation
            \vspace{0.5em}
        \item \brown{X}ccelerated linear algebra
    \end{itemize}

            \vspace{0.5em}
            \vspace{0.5em}

\end{frame}



\begin{frame}[fragile]
    
    \vspace{-1em}
    \begin{minted}{python}
import jax.numpy as jnp
from jax import grad, jit

def f(θ, x):
  for W, b in θ:
    w = W @ x + b
    x = jnp.tanh(w)  
  return x

def loss(θ, x, y):
  return jnp.sum((y - f(θ, x))**2)

grad_loss = jit(grad(loss))  # Now use gradient descent 
    \end{minted}

\end{frame}


\begin{frame}
    
    \Eg AlphaFold3 (Google JAX)

        \vspace{0.5em}
    \textbf{Highly accurate protein structure prediction with AlphaFold}

        \vspace{0.5em}
    John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
    Olaf Ronneberger, Kathryn Tunyasuvunakool,\ldots 

        \vspace{0.5em}
    \underline{Nature} Vol.\ 596 (2021)

    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \begin{itemize}
        \item Citation count $= ~30$K
        \vspace{0.5em}
        \item Nobel Prize in Chemistry 2024
    \end{itemize}

\end{frame}


\begin{frame}
    \frametitle{Functional Programming}
    
    JAX adopts a \emp{functional programming style}

    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}
    Key feature: Functions are pure

    \begin{itemize}
        \item Deterministic: same input $\implies$ same output 
        \item Have no side effects (don't modify state outside their scope)
    \end{itemize}

\end{frame}


\begin{frame}[fragile]

    A non-pure function

    \begin{minted}{python}
tax_rate = 0.1  # Global 
price = 10.0    # Global

def add_tax_non_pure():
    global price                
    # The next line both accesses and modifies global state
    price = price * (1 + tax_rate)    
    return price 
    \end{minted}
    
\end{frame}


\begin{frame}[fragile]

    A pure function

    \begin{minted}{python}

def add_tax_non_pure(price, tax_rate=0.1):
    price = price * (1 + tax_rate)    
    return price 
    \end{minted}
    
\end{frame}


\begin{frame}

    General advantages:

    \begin{itemize}
        \item Helps testing: each function can operate in isolation
        \item Data dependencies are explicit, which helps with understanding and optimizing complex computations 
        \item Promotes deterministic behavior and hence reproducibility
        \item Prevents subtle bugs that arise from mutating shared state
    \end{itemize}

\end{frame}



\begin{frame}
    
    Advantages for JAX:

     \begin{itemize}
         \item Functional programming facilitates autodiff because
             pure functions are more straightforward to differentiate (don't mod
             external state
         \item Pure functions are easier to
             parallelize and optimize for hardware accelerators like GPUs (don't
             depend on shared mutable state, more independence)
         \item Transformations can be composed cleanly with multiple
             transformations yielding predictable results
        \item Portability across hardware: The functional approach helps JAX
            create code that can run efficiently across different hardware
            accelerators without requiring hardware-specific implementations.
     \end{itemize}


\end{frame}

\begin{frame}
    \frametitle{JAX PyTrees}

    A PyTree is a concept in the JAX library that refers to a tree-like data structure built from Python containers.

    \Egs

    \begin{itemize}
        \item A dictionary of lists of parameters
        \item A list of dictionaries of parameters, etc.
    \end{itemize}

    JAX can

    \begin{itemize}
        \item apply functions to all leaves in a PyTree structure
        \item differentiate functions with respect to the leaves of PyTrees
        \item etc.
    \end{itemize}

\end{frame}


\begin{frame}
    
    
    \resizebox{1.0\textwidth}{!}{
        \input{pytree_fig}
    }

\end{frame}


\begin{frame}[fragile]
    
    \begin{minted}{python}
# Apply gradient updates to all parameters
def sgd_update(params, grads, learning_rate):
    return jax.tree_map(
        lambda p, g: p - learning_rate * g, 
        params, 
        grads
    )

# Calculate gradients (PyTree with same structure as params)
grads = jax.grad(loss_fn)(params, inputs, targets)

# Update all parameters at once
updated_params = sgd_update(params, grads, 0.01)    
    \end{minted}

\end{frame}


\begin{frame}
    
    Advantages over NumPy / MATLAB

    \vspace{0.5em}
    \begin{itemize}
        \item can specialize machine code based on parameter types / shapes
        \vspace{0.5em}
        \item automatically matches tasks with accelerators (GPU / TPU)
        \vspace{0.5em}
        \item fuses array operations for speed and memory efficiency
    \end{itemize}

\end{frame}

\begin{frame}

    Advantages of JAX (vs PyTorch / Numba / etc.) for economists:
    %
    \begin{itemize}
        \item exposes low level functions
            \vspace{0.5em}
        \item elegant functional programming style -- close to maths
            \vspace{0.5em}
        \item elegant autodiff tools
            \vspace{0.5em}
        \item array operations follow standard NumPy API
            \vspace{0.5em}
        \item automatic parallelization
            \vspace{0.5em}
        \item same code, multiple backends (CPUs, GPUs, TPUs)
    \end{itemize}

\end{frame}

\end{document}
